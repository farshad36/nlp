{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4P80_Seminar",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farshad36/nlp/blob/main/4P80_Seminar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q7bjLTa2ksR"
      },
      "source": [
        "Joel Gritter & Kindeep Singh Kargil\n",
        "\n",
        "COSC 4P80 - Seminar Demo\n",
        "\n",
        "March 29, 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z51tQN3V-5ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbce2a19-a53a-438d-db01-9156584276cc"
      },
      "source": [
        "# Music output\n",
        "!sudo apt-get install fluidsynth\n",
        "!pip install midi2audio\n",
        "!pip install mingus\n",
        "from mingus.containers import Note, NoteContainer, Track\n",
        "from mingus.midi.midi_file_out import write_NoteContainer, write_Track\n",
        "from midi2audio import FluidSynth\n",
        "\n",
        "fsy = FluidSynth()\n",
        "\n",
        "# imports for data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# imports for machine learning\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fluidsynth is already the newest version (1.1.9-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Requirement already satisfied: midi2audio in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: mingus in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mingus) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR_1giDiDHN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da996fe1-7b39-4159-87ab-6d0b1488944e"
      },
      "source": [
        "# read in the notes, make an array with 0's, except for the current note\n",
        "def read_and_format(input_filepath):\n",
        "  input_data = []\n",
        "  with open(input_filepath) as input_file:\n",
        "    for line in input_file:\n",
        "      values = line.split(\",\")\n",
        "      for value in values:\n",
        "        tmp = [0.0] * 88\n",
        "        v = int(value)\n",
        "        tmp[v-1] = 1.0\n",
        "        input_data.append(tmp)\n",
        "  \n",
        "  return input_data\n",
        "  \n",
        "\n",
        "input_data = read_and_format(\"k330-allegro-moderato.csv\")\n",
        "print(np.array(input_data).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2530, 88)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZmz0vCDrdfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4980abc8-ee75-4dfe-e491-bc3de8c932d0"
      },
      "source": [
        "# get the previous 20 notes, predict the next note\n",
        "def generate_datasets(input_array, n_prev = 20):\n",
        "  temp_x = [input_array[i:i+n_prev] for i in range(len(input_array) - n_prev)]\n",
        "  temp_y = [input_array[i+n_prev] for i in range(len(input_array) - n_prev)]\n",
        "\n",
        "  return np.array(temp_x), np.array(temp_y)\n",
        "\n",
        "x, y = generate_datasets(input_data)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, shuffle=False)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2008, 20, 88) (2008, 88)\n",
            "(502, 20, 88) (502, 88)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be0VQFAlqlPA"
      },
      "source": [
        "# build the model itself\n",
        "model = Sequential()\n",
        "model.add(LSTM(30))\n",
        "model.add(Dense(88, activation=\"softmax\"))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odZ6VCKIsLJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612213d4-1ff5-4fd8-c84c-ba3e773dde90"
      },
      "source": [
        "# train the model\n",
        "model.fit(x_train, y_train, batch_size=10, epochs=100, validation_split=0.05)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "191/191 [==============================] - 5s 13ms/step - loss: 3.7682 - accuracy: 0.1070 - val_loss: 2.4618 - val_accuracy: 0.1683\n",
            "Epoch 2/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.7116 - accuracy: 0.1572 - val_loss: 2.4907 - val_accuracy: 0.2178\n",
            "Epoch 3/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.6787 - accuracy: 0.1633 - val_loss: 2.4384 - val_accuracy: 0.1683\n",
            "Epoch 4/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.6604 - accuracy: 0.1742 - val_loss: 2.3921 - val_accuracy: 0.2178\n",
            "Epoch 5/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.5948 - accuracy: 0.2144 - val_loss: 2.3702 - val_accuracy: 0.2376\n",
            "Epoch 6/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.5757 - accuracy: 0.2170 - val_loss: 2.2860 - val_accuracy: 0.2475\n",
            "Epoch 7/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.4539 - accuracy: 0.2243 - val_loss: 2.1995 - val_accuracy: 0.3762\n",
            "Epoch 8/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.3824 - accuracy: 0.2513 - val_loss: 2.1476 - val_accuracy: 0.3564\n",
            "Epoch 9/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.3462 - accuracy: 0.2749 - val_loss: 2.0963 - val_accuracy: 0.3168\n",
            "Epoch 10/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.2402 - accuracy: 0.2996 - val_loss: 2.0346 - val_accuracy: 0.3168\n",
            "Epoch 11/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.1921 - accuracy: 0.3225 - val_loss: 1.9614 - val_accuracy: 0.3564\n",
            "Epoch 12/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.1196 - accuracy: 0.3231 - val_loss: 1.9348 - val_accuracy: 0.3564\n",
            "Epoch 13/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.0982 - accuracy: 0.3373 - val_loss: 1.8867 - val_accuracy: 0.3366\n",
            "Epoch 14/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.0016 - accuracy: 0.3659 - val_loss: 1.8375 - val_accuracy: 0.3465\n",
            "Epoch 15/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 2.0090 - accuracy: 0.3566 - val_loss: 1.8167 - val_accuracy: 0.3465\n",
            "Epoch 16/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.9546 - accuracy: 0.3878 - val_loss: 1.7468 - val_accuracy: 0.4257\n",
            "Epoch 17/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.9372 - accuracy: 0.3939 - val_loss: 1.7622 - val_accuracy: 0.3366\n",
            "Epoch 18/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.9062 - accuracy: 0.4101 - val_loss: 1.7279 - val_accuracy: 0.4257\n",
            "Epoch 19/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.8692 - accuracy: 0.4215 - val_loss: 1.7048 - val_accuracy: 0.3762\n",
            "Epoch 20/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.8900 - accuracy: 0.4194 - val_loss: 1.6882 - val_accuracy: 0.3861\n",
            "Epoch 21/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.8132 - accuracy: 0.4316 - val_loss: 1.6594 - val_accuracy: 0.3861\n",
            "Epoch 22/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.7937 - accuracy: 0.4280 - val_loss: 1.6232 - val_accuracy: 0.4356\n",
            "Epoch 23/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.7269 - accuracy: 0.4444 - val_loss: 1.6065 - val_accuracy: 0.4158\n",
            "Epoch 24/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.7141 - accuracy: 0.4542 - val_loss: 1.6120 - val_accuracy: 0.4356\n",
            "Epoch 25/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.6635 - accuracy: 0.4626 - val_loss: 1.6118 - val_accuracy: 0.3960\n",
            "Epoch 26/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.6122 - accuracy: 0.4799 - val_loss: 1.5974 - val_accuracy: 0.4455\n",
            "Epoch 27/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.6369 - accuracy: 0.4684 - val_loss: 1.5870 - val_accuracy: 0.4653\n",
            "Epoch 28/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.5958 - accuracy: 0.4858 - val_loss: 1.5564 - val_accuracy: 0.4554\n",
            "Epoch 29/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.5912 - accuracy: 0.5135 - val_loss: 1.5310 - val_accuracy: 0.4950\n",
            "Epoch 30/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.5457 - accuracy: 0.5151 - val_loss: 1.5330 - val_accuracy: 0.4653\n",
            "Epoch 31/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.5309 - accuracy: 0.5256 - val_loss: 1.4795 - val_accuracy: 0.4455\n",
            "Epoch 32/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.4858 - accuracy: 0.5310 - val_loss: 1.4973 - val_accuracy: 0.4554\n",
            "Epoch 33/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.4214 - accuracy: 0.5540 - val_loss: 1.4749 - val_accuracy: 0.4158\n",
            "Epoch 34/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.4336 - accuracy: 0.5680 - val_loss: 1.4602 - val_accuracy: 0.4851\n",
            "Epoch 35/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.4189 - accuracy: 0.5594 - val_loss: 1.4174 - val_accuracy: 0.4158\n",
            "Epoch 36/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.3288 - accuracy: 0.5954 - val_loss: 1.4354 - val_accuracy: 0.4455\n",
            "Epoch 37/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.3338 - accuracy: 0.5855 - val_loss: 1.4108 - val_accuracy: 0.4950\n",
            "Epoch 38/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.3050 - accuracy: 0.6008 - val_loss: 1.3775 - val_accuracy: 0.5050\n",
            "Epoch 39/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.2945 - accuracy: 0.6095 - val_loss: 1.3629 - val_accuracy: 0.4950\n",
            "Epoch 40/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.3012 - accuracy: 0.5987 - val_loss: 1.3415 - val_accuracy: 0.4851\n",
            "Epoch 41/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.2810 - accuracy: 0.6076 - val_loss: 1.3040 - val_accuracy: 0.5545\n",
            "Epoch 42/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.2429 - accuracy: 0.6347 - val_loss: 1.3141 - val_accuracy: 0.5149\n",
            "Epoch 43/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.2190 - accuracy: 0.6166 - val_loss: 1.3138 - val_accuracy: 0.5149\n",
            "Epoch 44/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.2034 - accuracy: 0.6432 - val_loss: 1.2901 - val_accuracy: 0.5050\n",
            "Epoch 45/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.1789 - accuracy: 0.6346 - val_loss: 1.2751 - val_accuracy: 0.5446\n",
            "Epoch 46/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.1848 - accuracy: 0.6482 - val_loss: 1.2940 - val_accuracy: 0.5248\n",
            "Epoch 47/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.1250 - accuracy: 0.6537 - val_loss: 1.2399 - val_accuracy: 0.5149\n",
            "Epoch 48/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.1516 - accuracy: 0.6503 - val_loss: 1.2216 - val_accuracy: 0.5743\n",
            "Epoch 49/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 1.0894 - accuracy: 0.6658 - val_loss: 1.2052 - val_accuracy: 0.5545\n",
            "Epoch 50/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.0905 - accuracy: 0.6672 - val_loss: 1.1989 - val_accuracy: 0.6238\n",
            "Epoch 51/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.0407 - accuracy: 0.6820 - val_loss: 1.1991 - val_accuracy: 0.5644\n",
            "Epoch 52/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.0419 - accuracy: 0.6733 - val_loss: 1.2202 - val_accuracy: 0.5644\n",
            "Epoch 53/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 1.0221 - accuracy: 0.6951 - val_loss: 1.1656 - val_accuracy: 0.5941\n",
            "Epoch 54/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.9880 - accuracy: 0.6916 - val_loss: 1.1390 - val_accuracy: 0.5941\n",
            "Epoch 55/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.9718 - accuracy: 0.7064 - val_loss: 1.1395 - val_accuracy: 0.6238\n",
            "Epoch 56/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.9549 - accuracy: 0.7157 - val_loss: 1.1725 - val_accuracy: 0.5842\n",
            "Epoch 57/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.9490 - accuracy: 0.7196 - val_loss: 1.1059 - val_accuracy: 0.6238\n",
            "Epoch 58/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.9131 - accuracy: 0.7270 - val_loss: 1.0787 - val_accuracy: 0.6337\n",
            "Epoch 59/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.8940 - accuracy: 0.7302 - val_loss: 1.1105 - val_accuracy: 0.6436\n",
            "Epoch 60/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.8976 - accuracy: 0.7486 - val_loss: 1.1753 - val_accuracy: 0.5446\n",
            "Epoch 61/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.8877 - accuracy: 0.7348 - val_loss: 1.0481 - val_accuracy: 0.6535\n",
            "Epoch 62/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.8641 - accuracy: 0.7406 - val_loss: 1.0596 - val_accuracy: 0.6436\n",
            "Epoch 63/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.8901 - accuracy: 0.7347 - val_loss: 1.0373 - val_accuracy: 0.6436\n",
            "Epoch 64/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.8377 - accuracy: 0.7570 - val_loss: 1.0646 - val_accuracy: 0.6436\n",
            "Epoch 65/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.8816 - accuracy: 0.7285 - val_loss: 1.0091 - val_accuracy: 0.6733\n",
            "Epoch 66/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.7505 - accuracy: 0.7887 - val_loss: 1.0236 - val_accuracy: 0.6436\n",
            "Epoch 67/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.7725 - accuracy: 0.7675 - val_loss: 1.0230 - val_accuracy: 0.6337\n",
            "Epoch 68/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.8120 - accuracy: 0.7518 - val_loss: 1.0050 - val_accuracy: 0.6139\n",
            "Epoch 69/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.8080 - accuracy: 0.7607 - val_loss: 0.9671 - val_accuracy: 0.6832\n",
            "Epoch 70/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.7317 - accuracy: 0.7880 - val_loss: 0.9626 - val_accuracy: 0.6832\n",
            "Epoch 71/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.7583 - accuracy: 0.7695 - val_loss: 1.0046 - val_accuracy: 0.6535\n",
            "Epoch 72/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.7480 - accuracy: 0.7749 - val_loss: 0.9505 - val_accuracy: 0.6634\n",
            "Epoch 73/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.7043 - accuracy: 0.8013 - val_loss: 0.9519 - val_accuracy: 0.7129\n",
            "Epoch 74/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.7249 - accuracy: 0.7904 - val_loss: 0.9559 - val_accuracy: 0.6733\n",
            "Epoch 75/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.7809 - accuracy: 0.7614 - val_loss: 0.9295 - val_accuracy: 0.7030\n",
            "Epoch 76/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.7087 - accuracy: 0.7901 - val_loss: 0.9102 - val_accuracy: 0.6931\n",
            "Epoch 77/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.7015 - accuracy: 0.7933 - val_loss: 0.9266 - val_accuracy: 0.7129\n",
            "Epoch 78/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.7256 - accuracy: 0.7905 - val_loss: 0.8792 - val_accuracy: 0.7228\n",
            "Epoch 79/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.6422 - accuracy: 0.8163 - val_loss: 0.8813 - val_accuracy: 0.6931\n",
            "Epoch 80/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.6398 - accuracy: 0.8168 - val_loss: 0.8906 - val_accuracy: 0.7129\n",
            "Epoch 81/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.6395 - accuracy: 0.8242 - val_loss: 0.8762 - val_accuracy: 0.7228\n",
            "Epoch 82/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.6104 - accuracy: 0.8348 - val_loss: 0.8853 - val_accuracy: 0.7228\n",
            "Epoch 83/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.5770 - accuracy: 0.8364 - val_loss: 0.8819 - val_accuracy: 0.7228\n",
            "Epoch 84/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.5797 - accuracy: 0.8455 - val_loss: 0.9440 - val_accuracy: 0.6733\n",
            "Epoch 85/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.6564 - accuracy: 0.8144 - val_loss: 0.8777 - val_accuracy: 0.7426\n",
            "Epoch 86/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.5941 - accuracy: 0.8393 - val_loss: 0.8423 - val_accuracy: 0.7327\n",
            "Epoch 87/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.5614 - accuracy: 0.8439 - val_loss: 0.8571 - val_accuracy: 0.7525\n",
            "Epoch 88/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.5550 - accuracy: 0.8574 - val_loss: 0.8049 - val_accuracy: 0.7723\n",
            "Epoch 89/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.5540 - accuracy: 0.8484 - val_loss: 0.7924 - val_accuracy: 0.7921\n",
            "Epoch 90/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.5305 - accuracy: 0.8585 - val_loss: 0.8567 - val_accuracy: 0.7525\n",
            "Epoch 91/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.5950 - accuracy: 0.8293 - val_loss: 0.8037 - val_accuracy: 0.7624\n",
            "Epoch 92/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.5203 - accuracy: 0.8730 - val_loss: 0.7729 - val_accuracy: 0.7624\n",
            "Epoch 93/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.5184 - accuracy: 0.8495 - val_loss: 0.8112 - val_accuracy: 0.8020\n",
            "Epoch 94/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.4932 - accuracy: 0.8665 - val_loss: 0.7923 - val_accuracy: 0.7624\n",
            "Epoch 95/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.5864 - accuracy: 0.8236 - val_loss: 0.7393 - val_accuracy: 0.7921\n",
            "Epoch 96/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.5226 - accuracy: 0.8567 - val_loss: 0.7541 - val_accuracy: 0.7822\n",
            "Epoch 97/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.4475 - accuracy: 0.8818 - val_loss: 0.7885 - val_accuracy: 0.7228\n",
            "Epoch 98/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.4831 - accuracy: 0.8715 - val_loss: 0.7534 - val_accuracy: 0.7921\n",
            "Epoch 99/100\n",
            "191/191 [==============================] - 2s 10ms/step - loss: 0.4875 - accuracy: 0.8663 - val_loss: 0.8230 - val_accuracy: 0.7327\n",
            "Epoch 100/100\n",
            "191/191 [==============================] - 2s 11ms/step - loss: 0.5021 - accuracy: 0.8695 - val_loss: 0.7409 - val_accuracy: 0.7624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6831c5cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucPR1Hp5vIUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8af91c-4c6e-4bb7-f56d-e0378922da43"
      },
      "source": [
        "# test the model\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.7729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7382884621620178, 0.7729083895683289]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPvGpGVwNIoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61d9cde-06cf-4bcf-da06-cd4c804bc090"
      },
      "source": [
        "# See incorrectly predicted \n",
        "predictions = model.predict(x_test)\n",
        "incorrect_indices = []\n",
        "for (index, (prediction, target)) in enumerate(zip(predictions, y_test)):\n",
        "  pred = np.argmax(prediction)\n",
        "  tar = np.argmax(target)\n",
        "  if pred != tar:\n",
        "    incorrect_indices.append(index)\n",
        "\n",
        "print(\", \".join(map(str, incorrect_indices)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7, 12, 16, 20, 25, 34, 51, 80, 84, 130, 131, 132, 133, 147, 149, 151, 152, 153, 154, 155, 161, 163, 169, 173, 180, 181, 185, 190, 195, 196, 200, 201, 202, 203, 215, 223, 224, 225, 233, 239, 240, 241, 246, 252, 255, 256, 258, 260, 270, 271, 272, 274, 277, 278, 281, 285, 290, 291, 303, 308, 311, 324, 326, 330, 332, 333, 334, 339, 341, 347, 352, 356, 357, 360, 361, 369, 374, 377, 390, 392, 396, 399, 401, 402, 405, 406, 409, 410, 418, 421, 422, 423, 425, 427, 440, 442, 444, 446, 447, 448, 450, 453, 454, 459, 465, 467, 469, 470, 476, 479, 481, 483, 494, 498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2WwsRUFm5u0"
      },
      "source": [
        "# initial - provide inital 20 notes\n",
        "# n - how many predicted notes to add (i.e. expand by this number)\n",
        "def make_big_song(initial, n):\n",
        "  res =[ x for x in initial]\n",
        "  for _ in range(n):\n",
        "    next = model.predict(np.array([res[-20:],]))[0]\n",
        "    res.append(next)\n",
        "\n",
        "  return np.array(res)\n",
        "\n",
        "# Expects n x 88\n",
        "def vector_to_midi(arr, filename=\"nice.midi\"):\n",
        "  track = Track()\n",
        "  for note_arr in arr:\n",
        "    note_num = int(np.argmax(note_arr))\n",
        "    note = Note()\n",
        "    note.from_int(note_num - 3)\n",
        "    track.add_notes(note)\n",
        "  write_Track(filename, track)\n",
        "  print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7AKlNEV4THd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d6a47f-c5d8-49fc-a6b5-ae49e66f0072"
      },
      "source": [
        "full = make_big_song(np.array(input_data[:20]), len(input_data) - 20)\n",
        "\n",
        "vector_to_midi(full, \"full_predicted.midi\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXdjXdBXQ1Hs",
        "outputId": "d66adb21-cc85-42f0-8e92-e003ed805c6a"
      },
      "source": [
        "def predict_to_file(first_20_notes, expected, filename=\"nice\"):\n",
        "  next = model.predict(np.array([first_20_notes]))\n",
        "  actual_next = np.array([expected])\n",
        "  next_file = filename + \"_predicted_note\"\n",
        "  actual_next_file = filename + \"_actual_note\"\n",
        "  orig_file = filename + \"_first_20_notes\"\n",
        "\n",
        "  vector_to_midi(next, next_file + \".midi\")\n",
        "  vector_to_midi(actual_next, actual_next_file + \".midi\")\n",
        "  vector_to_midi(first_20_notes, orig_file + \".midi\")\n",
        "\n",
        "  # This conversion not seem to work\n",
        "  # fsy.midi_to_audio(next_file + \".midi\", next_file + \".mp3\")\n",
        "  # fsy.midi_to_audio(actual_next_file + \".midi\", actual_next_file + \".mp3\")\n",
        "  # fsy.midi_to_audio(orig_file + \".midi\",  orig_file + \".mp3\")\n",
        "\n",
        "predict_to_file(test_in, test_out)\n",
        "\n",
        "inci = incorrect_indices[0]\n",
        "predict_to_file(x_test[inci], y_test[inci], 'first_incorrect')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n",
            "Done!\n",
            "Done!\n",
            "Done!\n",
            "Done!\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}